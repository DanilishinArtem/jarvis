{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from ollama import Client\n",
    "from TTS.api import TTS\n",
    "\n",
    "# Part of initialization of chatbot (llama3.1) --------->\n",
    "client = Client(\n",
    "  host='http://localhost:11434',\n",
    "  headers={'model': 'llama3.1:latest'}\n",
    ")\n",
    "\n",
    "messages=[\n",
    "    {\"role\": \"user\", \"content\": \"Привет, Джарвис. Что у нас на сегодня?\"}\n",
    "]\n",
    "\n",
    "# Part of initialization of TTS model (TTS) --------->\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Представь что ты Джарвис из фильма Железный Человек, общайся так, как он бы общался с Тони Старком, а я буду Тони Старком. Вот мой запрос: \"\n",
    "message = \"Привет, Джарвис, Что у нас сегодня запланировано?\"\n",
    "whole_message = prompt + message\n",
    "messages=[\n",
    "    {\"role\": \"user\", \"content\": f\"{whole_message}\"}\n",
    "]\n",
    "\n",
    "response = client.chat(\n",
    "    model='llama3.1:latest',\n",
    "    messages=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tts.tts_to_file(text=response[\"message\"][\"content\"], speaker_wav=\"/Users/adanilishin/jarvis/jarvis_sample.wav\", language=\"ru\", file_path=\"jarvis_answer.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import soundfile as sf\n",
    "import sounddevice as sd\n",
    "from TTS.api import TTS\n",
    "\n",
    "# Init TTS\n",
    "# tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\")\n",
    "\n",
    "# Init Ollama\n",
    "messages = [{\"role\": \"user\", \"content\": \"Привет, Джарвис. Что у нас сегодня запланировано?\"}]\n",
    "\n",
    "buffer = \"\"\n",
    "for chunk in ollama.chat(model=\"llama3.1:latest\", messages=messages, stream=True):\n",
    "    text_piece = chunk[\"message\"][\"content\"]\n",
    "    print(text_piece, end=\"\", flush=True)\n",
    "    buffer += text_piece\n",
    "\n",
    "    # Check if we reached sentence boundary\n",
    "    if any(buffer.endswith(p) for p in [\".\", \"!\", \"?\", \"…\"]):\n",
    "        # Synthesize and play\n",
    "        wav = tts.tts(buffer, speaker_wav=\"jarvis_sample.wav\", language=\"ru\")\n",
    "        sd.play(wav, samplerate=24000)\n",
    "        sd.wait()\n",
    "        buffer = \"\"  # reset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Здравствуйте! Nothing on the agenda for > Text splitted to sentences.\n",
      "['Здравствуйте!', 'Nothing on the agenda for']\n",
      " > Processing time: 23.757390022277832\n",
      " > Real-time factor: 3.1817933065550665\n",
      " now. How about you? What would > Text splitted to sentences.\n",
      "['now.', 'How about you?', 'What would']\n",
      " > Processing time: 17.329724073410034\n",
      " > Real-time factor: 2.2473441223927924\n",
      " you like to do? I'm happy > Text splitted to sentences.\n",
      "['you like to do?', \"I'm happy\"]\n",
      " > Processing time: 10.218785047531128\n",
      " > Real-time factor: 2.5356073359072444\n",
      " to chat or help with something > Text splitted to sentences.\n",
      "['to chat or help with something']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     33\u001b[39m words = words[CHUNK_WORDS:]\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Синтез речи\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m wav = \u001b[43mtts\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspeaker_wav\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mjarvis_sample.wav\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mru\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     40\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Преобразуем и проигрываем сразу\u001b[39;00m\n\u001b[32m     43\u001b[39m wav = np.array(wav, dtype=np.float32)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Users/adanilishin/jarvis/TTS/TTS/api.py:276\u001b[39m, in \u001b[36mTTS.tts\u001b[39m\u001b[34m(self, text, speaker, language, speaker_wav, emotion, speed, split_sentences, **kwargs)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Convert text to speech.\u001b[39;00m\n\u001b[32m    249\u001b[39m \n\u001b[32m    250\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    271\u001b[39m \u001b[33;03m        Additional arguments for the model.\u001b[39;00m\n\u001b[32m    272\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    273\u001b[39m \u001b[38;5;28mself\u001b[39m._check_arguments(\n\u001b[32m    274\u001b[39m     speaker=speaker, language=language, speaker_wav=speaker_wav, emotion=emotion, speed=speed, **kwargs\n\u001b[32m    275\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m wav = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msynthesizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspeaker_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspeaker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlanguage_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspeaker_wav\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspeaker_wav\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreference_wav\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstyle_wav\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstyle_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreference_speaker_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m    \u001b[49m\u001b[43msplit_sentences\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit_sentences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wav\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Users/adanilishin/jarvis/TTS/TTS/utils/synthesizer.py:386\u001b[39m, in \u001b[36mSynthesizer.tts\u001b[39m\u001b[34m(self, text, speaker_name, language_name, speaker_wav, style_wav, style_text, reference_wav, reference_speaker_name, split_sentences, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sen \u001b[38;5;129;01min\u001b[39;00m sens:\n\u001b[32m    385\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.tts_model, \u001b[33m\"\u001b[39m\u001b[33msynthesize\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m         outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtts_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43msynthesize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43msen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtts_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m            \u001b[49m\u001b[43mspeaker_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspeaker_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvoice_dirs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvoice_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[43md_vector\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspeaker_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m            \u001b[49m\u001b[43mspeaker_wav\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspeaker_wav\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlanguage_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    396\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    397\u001b[39m         \u001b[38;5;66;03m# synthesize voice\u001b[39;00m\n\u001b[32m    398\u001b[39m         outputs = synthesis(\n\u001b[32m    399\u001b[39m             model=\u001b[38;5;28mself\u001b[39m.tts_model,\n\u001b[32m    400\u001b[39m             text=sen,\n\u001b[32m   (...)\u001b[39m\u001b[32m    408\u001b[39m             language_id=language_id,\n\u001b[32m    409\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Users/adanilishin/jarvis/TTS/TTS/tts/models/xtts.py:419\u001b[39m, in \u001b[36mXtts.synthesize\u001b[39m\u001b[34m(self, text, config, speaker_wav, language, speaker_id, **kwargs)\u001b[39m\n\u001b[32m    412\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.inference(text, language, gpt_cond_latent, speaker_embedding, **settings)\n\u001b[32m    413\u001b[39m settings.update({\n\u001b[32m    414\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgpt_cond_len\u001b[39m\u001b[33m\"\u001b[39m: config.gpt_cond_len,\n\u001b[32m    415\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgpt_cond_chunk_len\u001b[39m\u001b[33m\"\u001b[39m: config.gpt_cond_chunk_len,\n\u001b[32m    416\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmax_ref_len\u001b[39m\u001b[33m\"\u001b[39m: config.max_ref_len,\n\u001b[32m    417\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msound_norm_refs\u001b[39m\u001b[33m\"\u001b[39m: config.sound_norm_refs,\n\u001b[32m    418\u001b[39m })\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfull_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeaker_wav\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Users/adanilishin/jarvis/TTS/TTS/tts/models/xtts.py:488\u001b[39m, in \u001b[36mXtts.full_inference\u001b[39m\u001b[34m(self, text, ref_audio_path, language, temperature, length_penalty, repetition_penalty, top_k, top_p, do_sample, gpt_cond_len, gpt_cond_chunk_len, max_ref_len, sound_norm_refs, **hf_generate_kwargs)\u001b[39m\n\u001b[32m    441\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    442\u001b[39m \u001b[33;03mThis function produces an audio clip of the given text being spoken with the given reference voice.\u001b[39;00m\n\u001b[32m    443\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    478\u001b[39m \u001b[33;03m    Sample rate is 24kHz.\u001b[39;00m\n\u001b[32m    479\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    480\u001b[39m (gpt_cond_latent, speaker_embedding) = \u001b[38;5;28mself\u001b[39m.get_conditioning_latents(\n\u001b[32m    481\u001b[39m     audio_path=ref_audio_path,\n\u001b[32m    482\u001b[39m     gpt_cond_len=gpt_cond_len,\n\u001b[32m   (...)\u001b[39m\u001b[32m    485\u001b[39m     sound_norm_refs=sound_norm_refs,\n\u001b[32m    486\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgpt_cond_latent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspeaker_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlength_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlength_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhf_generate_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Users/adanilishin/jarvis/TTS/TTS/tts/models/xtts.py:577\u001b[39m, in \u001b[36mXtts.inference\u001b[39m\u001b[34m(self, text, language, gpt_cond_latent, speaker_embedding, temperature, length_penalty, repetition_penalty, top_k, top_p, do_sample, num_beams, speed, enable_text_splitting, **hf_generate_kwargs)\u001b[39m\n\u001b[32m    572\u001b[39m             gpt_latents = F.interpolate(\n\u001b[32m    573\u001b[39m                 gpt_latents.transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m), scale_factor=length_scale, mode=\u001b[33m\"\u001b[39m\u001b[33mlinear\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    574\u001b[39m             ).transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    576\u001b[39m         gpt_latents_list.append(gpt_latents.cpu())\n\u001b[32m--> \u001b[39m\u001b[32m577\u001b[39m         wavs.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhifigan_decoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgpt_latents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspeaker_embedding\u001b[49m\u001b[43m)\u001b[49m.cpu().squeeze())\n\u001b[32m    579\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    580\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mwav\u001b[39m\u001b[33m\"\u001b[39m: torch.cat(wavs, dim=\u001b[32m0\u001b[39m).numpy(),\n\u001b[32m    581\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgpt_latents\u001b[39m\u001b[33m\"\u001b[39m: torch.cat(gpt_latents_list, dim=\u001b[32m1\u001b[39m).numpy(),\n\u001b[32m    582\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mspeaker_embedding\u001b[39m\u001b[33m\"\u001b[39m: speaker_embedding,\n\u001b[32m    583\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Users/adanilishin/jarvis/TTS/TTS/tts/layers/xtts/hifigan_decoder.py:700\u001b[39m, in \u001b[36mHifiDecoder.forward\u001b[39m\u001b[34m(self, latents, g)\u001b[39m\n\u001b[32m    694\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output_sample_rate != \u001b[38;5;28mself\u001b[39m.input_sample_rate:\n\u001b[32m    695\u001b[39m     z = torch.nn.functional.interpolate(\n\u001b[32m    696\u001b[39m         z,\n\u001b[32m    697\u001b[39m         scale_factor=[\u001b[38;5;28mself\u001b[39m.output_sample_rate / \u001b[38;5;28mself\u001b[39m.input_sample_rate],\n\u001b[32m    698\u001b[39m         mode=\u001b[33m\"\u001b[39m\u001b[33mlinear\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    699\u001b[39m     ).squeeze(\u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m700\u001b[39m o = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwaveform_decoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m o\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Users/adanilishin/jarvis/TTS/TTS/tts/layers/xtts/hifigan_decoder.py:294\u001b[39m, in \u001b[36mHifiganGenerator.forward\u001b[39m\u001b[34m(self, x, g)\u001b[39m\n\u001b[32m    292\u001b[39m             z_sum = \u001b[38;5;28mself\u001b[39m.resblocks[i * \u001b[38;5;28mself\u001b[39m.num_kernels + j](o)\n\u001b[32m    293\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m             z_sum += \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mresblocks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_kernels\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    295\u001b[39m     o = z_sum / \u001b[38;5;28mself\u001b[39m.num_kernels\n\u001b[32m    296\u001b[39m o = F.leaky_relu(o)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Users/adanilishin/jarvis/TTS/TTS/tts/layers/xtts/hifigan_decoder.py:118\u001b[39m, in \u001b[36mResBlock1.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    116\u001b[39m     xt = c1(xt)\n\u001b[32m    117\u001b[39m     xt = F.leaky_relu(xt, LRELU_SLOPE)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     xt = \u001b[43mc2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m     x = xt + x\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/nn/modules/conv.py:310\u001b[39m, in \u001b[36mConv1d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/nn/modules/conv.py:306\u001b[39m, in \u001b[36mConv1d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m'\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv1d(F.pad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode),\n\u001b[32m    304\u001b[39m                     weight, bias, \u001b[38;5;28mself\u001b[39m.stride,\n\u001b[32m    305\u001b[39m                     _single(\u001b[32m0\u001b[39m), \u001b[38;5;28mself\u001b[39m.dilation, \u001b[38;5;28mself\u001b[39m.groups)\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "from TTS.api import TTS\n",
    "\n",
    "# # -------------------------------\n",
    "# # 1. Init TTS\n",
    "# # -------------------------------\n",
    "# tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\", gpu=True)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Init Ollama\n",
    "# -------------------------------\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Привет, Джарвис. Что у нас сегодня запланировано?\"}\n",
    "]\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Streaming loop\n",
    "# -------------------------------\n",
    "buffer = \"\"\n",
    "CHUNK_WORDS = 6   # каждые 6 слов синтезируем звук\n",
    "\n",
    "for chunk in ollama.chat(model=\"llama3.1:latest\", messages=messages, stream=True):\n",
    "    text_piece = chunk[\"message\"][\"content\"]\n",
    "    print(text_piece, end=\"\", flush=True)\n",
    "    buffer += text_piece + \" \"\n",
    "\n",
    "    words = buffer.split()\n",
    "    # Если накопили достаточно слов → синтезируем и проигрываем\n",
    "    while len(words) >= CHUNK_WORDS:\n",
    "        chunk_text = \" \".join(words[:CHUNK_WORDS])\n",
    "        words = words[CHUNK_WORDS:]\n",
    "\n",
    "        # Синтез речи\n",
    "        wav = tts.tts(\n",
    "            text=chunk_text,\n",
    "            speaker_wav=\"jarvis_sample.wav\",\n",
    "            language=\"ru\"\n",
    "        )\n",
    "\n",
    "        # Преобразуем и проигрываем сразу\n",
    "        wav = np.array(wav, dtype=np.float32)\n",
    "        sd.play(wav, samplerate=24000)\n",
    "        sd.wait()\n",
    "\n",
    "    buffer = \" \".join(words)\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Остаток (если есть)\n",
    "# -------------------------------\n",
    "if buffer.strip():\n",
    "    wav = tts.tts(\n",
    "        text=buffer,\n",
    "        speaker_wav=\"jarvis_sample.wav\",\n",
    "        language=\"ru\"\n",
    "    )\n",
    "    wav = np.array(wav, dtype=np.float32)\n",
    "    sd.play(wav, samplerate=24000)\n",
    "    sd.wait()\n",
    "\n",
    "print(\"\\n[INFO] Jarvis закончил говорить ✅\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
